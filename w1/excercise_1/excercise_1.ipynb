{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92e3bc3",
   "metadata": {
    "vscode": {
     "languageId": "latex"
    }
   },
   "source": [
    "# 1 Laplace Distribution MLE Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6696a",
   "metadata": {},
   "source": [
    "## 1.1 Mathematical Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2e098d",
   "metadata": {},
   "source": [
    "### 1.1.1 True data generating process for a Laplace distribution with parameters $\\mu$ (location) and $b$ (scale)\n",
    "\n",
    "$$\n",
    "X_i \\sim  Laplace(\\mu, b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556eb161",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1.2 Probability Density Function\n",
    "$$\n",
    "p(x|\\mu, b) = \\frac{1}{2b} \\exp (-\\frac{|x-\\mu|}{b})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0a5f4f",
   "metadata": {},
   "source": [
    "### 1.1.3 Observed data notation for $T$ samples\n",
    "$$\n",
    "\\tilde{X}_i \\sim p(x|\\mu, b) \\quad \\text{for } i=1,\\dots,T \\\\\n",
    "\\tilde{y}_i \\sim p(y|X, \\mu, b) \\quad \\text{for } i=1,\\dots,T \\\\\n",
    "$$\n",
    "realizations from the true distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc261d2b",
   "metadata": {},
   "source": [
    "### 1.1.4 Candidate model specification using asterisk notation\n",
    "$$\n",
    "\\begin{align}\n",
    "y_i^* =& f^*(X_i^*|\\theta^*) + \\epsilon_i^* \\\\\n",
    "\\epsilon^*_i \\sim& p^*( \\epsilon^*| \\theta) \\\\\n",
    "y_i^* \\sim& p^*(y^*|X^*_i, \\theta^*)\n",
    "\\end {align}\n",
    "$$\n",
    "\n",
    "\n",
    "according to the script we would have $\\epsilon^*_i \\sim p^*( \\epsilon*| \\theta)$ but that makes no sense to me. why are we drawing from laplace? Shouldnt we draw from the normal distribution?\n",
    "\n",
    "i think there is abuse of notation on script  page 16 arent we using p* for multiple things?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be16ce79",
   "metadata": {},
   "source": [
    "### 1.1.5 Likelihood and Log-Likelihood functions\n",
    "Given observed samples $\\{\\tilde{X}_i\\}_{i=1}^T$\n",
    "\n",
    "**Likelihood function**\n",
    "How likely the datapoints are given our distribution and parameters\n",
    "$$\n",
    "\\tilde{\\mathcal{L}}(\\tilde{\\theta}) = \\prod_{i=1}^T \\tilde{p}(\\tilde{X_i}|\\tilde{\\theta})\n",
    "$$\n",
    "\n",
    "\n",
    "**Log-Likelihood function**\n",
    "$$\n",
    "\\tilde{\\ell}(\\tilde{\\theta}) = \\sum_{i=1}^T \\log \\tilde{p}(\\tilde{X_i}|\\tilde{\\theta})\n",
    "$$\n",
    "\n",
    "REMINDER: log 1 = 0, log 0.5 = -0.30, log 0.2 =  -0.69 etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c9a56",
   "metadata": {},
   "source": [
    "### 1.1.6 MLE Optimization Problem\n",
    "$$\n",
    "\\hat \\theta = \\arg \\max_{\\tilde{\\theta}} \\sum_{i=1}^T \\log \\tilde{p}(\\tilde{X_i}|\\tilde{\\theta}) \\\\\n",
    "\\hat \\theta = \\arg \\max_{\\tilde{\\theta}} \\tilde{\\ell}(\\tilde{\\theta})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae878468",
   "metadata": {},
   "source": [
    "### 1.1.7 Estimated Model specification after optimization\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat\\theta &= \\arg \\min_{\\theta^*} L^*(\\theta^*) \\\\\n",
    "\\hat y_i &= \\hat f(X_i^*|\\hat \\theta) \\\\\n",
    "\\hat y_i &\\sim \\hat p(\\hat y | X_i^*, \\hat \\theta)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Just everything with the estimated parameters that minimize the loss function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4241b4a",
   "metadata": {},
   "source": [
    "## 1.2 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ec7b9",
   "metadata": {},
   "source": [
    "### 1.2.1 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8486f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed = 42\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba48a7e",
   "metadata": {},
   "source": [
    "### 1.2.2 True Data generation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_laplace_data(mu, b, n, K: int):\n",
    "    \"\"\" Generate K datasets of n samples from Laplace distribution with parameters mu and b \"\"\"\n",
    "    X = np.random.laplace(mu, b, (K, n) if K > 1 else n)\n",
    "    noise = np.random.normal(0, 1, (K, n) if K > 1 else n)\n",
    "    return X + noise # not sure if the noise should be normal or laplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3ae78f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_pdf(x, mu, b):\n",
    "    \"\"\" Probability density function of the Laplace distribution \"\"\"\n",
    "    return (1 / (2 * b)) * np.exp(-np.abs(x - mu) / b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a85092",
   "metadata": {},
   "source": [
    "### 1.2.3 MLE Estimation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef4156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLE_laplace_est(X):\n",
    "    \"\"\" Compute MLE estimates for parameters of Laplace distribution given data X.\n",
    "        X is a 2D array where each row is a dataset.\n",
    "        Returns two 1D arrays: mu_hats and b_hats, containing the estimates for each dataset.\n",
    "    \"\"\"\n",
    "    n = X.shape[1]\n",
    "    K = X.shape[0]\n",
    "    \n",
    "    # sample median\n",
    "    mu_hats = np.median(X, axis=1)\n",
    "    # mean absolute deviation from median\n",
    "    b_hats = (1/n)*np.sum([np.abs(X[k] - mu_hats[k]) for k in range(K)], axis=1) \n",
    "\n",
    "    return mu_hats, b_hats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c6b284",
   "metadata": {},
   "source": [
    "### 1.2.4 Simulation Loop & Result Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efd6cbd",
   "metadata": {},
   "source": [
    "With simple for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba08535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples per experiment\n",
    "n = 1000\n",
    "# number of experiments\n",
    "K = 500\n",
    "\n",
    "# true parameters\n",
    "mu = 0 # location\n",
    "b = 2 # scale\n",
    "\n",
    "\n",
    "X = np.zeros((K,n))\n",
    "theta_hats = np.zeros((K,2))\n",
    "for k in range(K):\n",
    "    X[k] = np.random.laplace(mu, b, n)\n",
    "    \n",
    "    mu_hat = np.median(X[k])\n",
    "    b_hat = (1/n)*sum(np.abs(X[k] - mu_hat))\n",
    "    theta_hats[k] = (mu_hat, b_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7086a0d",
   "metadata": {},
   "source": [
    "Optimized operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8803db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of samples per experiment\n",
    "n = 1000\n",
    "# number of experiments\n",
    "K = 500\n",
    "\n",
    "# true parameters\n",
    "mu = 0 # location\n",
    "b = 2 # scale\n",
    "\n",
    "X = generate_laplace_data(mu, b, n, K)\n",
    "y_true  = laplace_pdf(X, mu, b)\n",
    "mu_hats, b_hats = MLE_laplace_est(X)\n",
    "theta_hats = np.column_stack((mu_hats, b_hats))\n",
    "\n",
    "mu_hats_mean = np.mean(mu_hats)\n",
    "mu_hats_std = np.std(mu_hats)\n",
    "\n",
    "b_hats_mean = np.mean(b_hats)\n",
    "b_hats_std = np.std(b_hats)\n",
    "\n",
    "y_hats = laplace_pdf(X, mu_hats_mean, b_hats_mean)\n",
    "\n",
    "residuals = y_true - y_hats\n",
    "# mle error variance estimate\n",
    "sigma2_hat = np.sum(residuals**2) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a465c598",
   "metadata": {},
   "source": [
    "### 1.2.5 Summary Stats and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fbb47e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation settings:\n",
      "Number of samples per simulation (n): 1000\n",
      "Number of repetitions (K): 500\n",
      "\n",
      "Laplace Distribution - True parameters:\n",
      "mu = 0 (location)\n",
      "b = 2 (scale)\n",
      "\n",
      "Laplace Distribution - Estimated parameters (mean over 500 simulations):\n",
      "mu_hat = -0.00225510 (location)\n",
      "b_hat = 1.99805678 (scale)\n",
      "\n",
      "Standard deviation of estimates over 500 simulations:\n",
      "std(mu_hat) = 0.06814306 (location)\n",
      "std(b_hat) = 0.06004149 (scale)\n",
      "\n",
      "MLE error variance estimate (sigma^2_hat): 0.00001873\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Simulation settings:\")\n",
    "print(f\"Number of samples per simulation (n): {n}\")\n",
    "print(f\"Number of repetitions (K): {K}\")\n",
    "print(f\"\\nLaplace Distribution - True parameters:\")\n",
    "print(f\"mu = {mu} (location)\")\n",
    "print(f\"b = {b} (scale)\")\n",
    "print(f\"\\nLaplace Distribution - Estimated parameters (mean over {K} simulations):\")\n",
    "print(f\"mu_hat = {mu_hats_mean:.8f} (location)\")\n",
    "print(f\"b_hat = {b_hats_mean:.8f} (scale)\")\n",
    "print(f\"\\nStandard deviation of estimates over {K} simulations:\")\n",
    "print(f\"std(mu_hat) = {mu_hats_std:.8f} (location)\")\n",
    "print(f\"std(b_hat) = {b_hats_std:.8f} (scale)\")\n",
    "print(f\"\\nMLE error variance estimate (sigma^2_hat): {sigma2_hat:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57003135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(mu, b, n, K):\n",
    "    X = generate_laplace_data(mu, b, n, K)\n",
    "    mu_hats, b_hats = MLE_laplace_est(X)\n",
    "    theta_hats = np.column_stack((mu_hats, b_hats))\n",
    "    return theta_hats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13bd3ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
